// Orleans.GpuBridge - GPU-native distributed computing for Microsoft Orleans
// Copyright (c) 2025 Michael Ivertowski

using System;
using System.Collections.Concurrent;
using System.Collections.Generic;
using System.Threading;
using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using Orleans;
using Orleans.GpuBridge.Abstractions.RingKernels;
using Orleans.GpuBridge.Abstractions.Temporal;
using Orleans.Runtime;

namespace Orleans.GpuBridge.Grains.Base;

/// <summary>
/// Delegate for fire-and-forget handler operations that modify state by reference.
/// </summary>
/// <typeparam name="TRequest">Request message type (blittable struct)</typeparam>
/// <typeparam name="TState">Actor state type (blittable struct)</typeparam>
/// <param name="request">Request payload</param>
/// <param name="state">Actor state (modified by reference)</param>
public delegate void FireAndForgetHandler<TRequest, TState>(TRequest request, ref TState state)
    where TRequest : unmanaged
    where TState : unmanaged;

/// <summary>
/// Base class for source-generated GPU-native actors.
/// Provides runtime support for generated handler dispatch, CPU fallback, and temporal ordering.
/// </summary>
/// <typeparam name="TState">Actor state type (must be blittable struct for GPU memory)</typeparam>
/// <remarks>
/// <para>
/// <strong>Purpose:</strong>
/// This class serves as the runtime base for actors generated by the GpuNativeActorGenerator.
/// Generated grains inherit from this class and override handler methods.
/// </para>
///
/// <para>
/// <strong>Generated Code Pattern:</strong>
/// <code>
/// // Source generator produces:
/// public partial class CalculatorActorGrain : GeneratedActorBase&lt;CalculatorActorState&gt;
/// {
///     protected override Task&lt;object?&gt; DispatchHandlerAsync(int handlerId, ReadOnlyMemory&lt;byte&gt; payload)
///     {
///         return handlerId switch
///         {
///             1 => InvokeAddHandler(payload),
///             2 => InvokeMultiplyHandler(payload),
///             _ => throw new InvalidOperationException($"Unknown handler: {handlerId}")
///         };
///     }
/// }
/// </code>
/// </para>
///
/// <para>
/// <strong>Handler Invocation Flow:</strong>
/// <list type="number">
/// <item>Message arrives via Orleans grain method</item>
/// <item>Message serialized to blittable payload</item>
/// <item>GPU kernel invoked via ring kernel queue</item>
/// <item>If GPU unavailable, CPU fallback executes</item>
/// <item>Response deserialized and returned</item>
/// </list>
/// </para>
/// </remarks>
public abstract class GeneratedActorBase<TState> : Grain, IGrainBase
    where TState : unmanaged
{
    private readonly ILogger _logger;
    private readonly IGrainContext _grainContext;
    private readonly IRingKernelBridge? _ringKernelBridge;
    private readonly ConcurrentDictionary<int, HandlerMetrics> _handlerMetrics = new();

    private bool _isInitialized;
    private bool _isGpuAvailable;
    private int _gpuDeviceId;
    private long _totalMessagesProcessed;
    private long _gpuExecutions;
    private long _cpuFallbacks;

    private GpuStateHandle<TState>? _stateHandle;

    /// <summary>
    /// Current actor state (GPU-resident or CPU shadow copy).
    /// When using GPU, this is synchronized with the GpuStateHandle.
    /// </summary>
    protected TState State;

    /// <summary>
    /// Hybrid Logical Clock for temporal ordering
    /// </summary>
    protected HybridTimestamp CurrentTimestamp { get; private set; }

    /// <summary>
    /// Whether GPU acceleration is available for this actor
    /// </summary>
    protected bool IsGpuAvailable => _isGpuAvailable;

    /// <summary>
    /// GPU device ID this actor is bound to
    /// </summary>
    protected int GpuDeviceId => _gpuDeviceId;

    /// <summary>
    /// Total messages processed by this actor
    /// </summary>
    public long TotalMessagesProcessed => _totalMessagesProcessed;

    /// <summary>
    /// Number of executions on GPU
    /// </summary>
    public long GpuExecutions => _gpuExecutions;

    /// <summary>
    /// Number of CPU fallback executions
    /// </summary>
    public long CpuFallbacks => _cpuFallbacks;

    /// <summary>
    /// Gets the GPU state handle for direct GPU memory access.
    /// </summary>
    /// <remarks>
    /// Use this for advanced scenarios where direct GPU state manipulation is required.
    /// For normal operations, use the <see cref="State"/> property which is automatically synchronized.
    /// </remarks>
    protected GpuStateHandle<TState>? GpuStateHandle => _stateHandle;

    /// <summary>
    /// Gets the ring kernel bridge for GPU operations.
    /// </summary>
    protected IRingKernelBridge? RingKernelBridge => _ringKernelBridge;

    /// <summary>
    /// Initializes a new instance of the <see cref="GeneratedActorBase{TState}"/> class.
    /// </summary>
    /// <param name="grainContext">Orleans grain context.</param>
    /// <param name="logger">Logger instance.</param>
    /// <param name="ringKernelBridge">
    /// Optional ring kernel bridge for GPU execution. When provided, enables GPU-accelerated
    /// handler execution. When null, uses CPU-only execution mode.
    /// </param>
    protected GeneratedActorBase(
        IGrainContext grainContext,
        ILogger logger,
        IRingKernelBridge? ringKernelBridge = null)
    {
        _grainContext = grainContext ?? throw new ArgumentNullException(nameof(grainContext));
        _logger = logger ?? throw new ArgumentNullException(nameof(logger));
        _ringKernelBridge = ringKernelBridge;
    }

    IGrainContext IGrainBase.GrainContext => _grainContext;

    /// <summary>
    /// Activates the generated actor and initializes GPU resources.
    /// </summary>
    public override async Task OnActivateAsync(CancellationToken cancellationToken)
    {
        try
        {
            var actorId = TryGetActorId();
            _logger.LogInformation(
                "Activating generated actor {ActorType} with ID {ActorId}",
                GetType().Name,
                actorId);

            // Initialize state to default
            State = default;

            // Initialize HLC timestamp
            CurrentTimestamp = HybridTimestamp.Now();

            // Check GPU availability via bridge if available
            if (_ringKernelBridge != null)
            {
                _isGpuAvailable = await _ringKernelBridge.IsGpuAvailableAsync(cancellationToken);
                _gpuDeviceId = await _ringKernelBridge.GetDevicePlacementAsync(actorId, cancellationToken);

                // Allocate GPU state if GPU is available
                if (_isGpuAvailable && _gpuDeviceId >= 0)
                {
                    _stateHandle = await _ringKernelBridge.AllocateStateAsync<TState>(
                        actorId,
                        _gpuDeviceId,
                        cancellationToken);

                    _logger.LogDebug(
                        "Allocated GPU state for actor {ActorId} on device {DeviceId} " +
                        "(Size: {SizeBytes} bytes, GPU: {IsGpuResident})",
                        actorId,
                        _gpuDeviceId,
                        _stateHandle.SizeBytes,
                        _stateHandle.IsValid);
                }
            }
            else
            {
                // Fallback to virtual method check (for backwards compatibility)
                _isGpuAvailable = await CheckGpuAvailabilityAsync(cancellationToken);
                _gpuDeviceId = await DetermineGpuDevicePlacementAsync(cancellationToken);
            }

            // Allow derived class to configure
            await ConfigureActorAsync(cancellationToken);

            _isInitialized = true;

            _logger.LogInformation(
                "Generated actor {ActorType} activated successfully (GPU: {IsGpu}, Device: {DeviceId}, Bridge: {HasBridge})",
                GetType().Name,
                _isGpuAvailable,
                _gpuDeviceId,
                _ringKernelBridge != null);
        }
        catch (Exception ex)
        {
            _logger.LogError(
                ex,
                "Failed to activate generated actor {ActorType}",
                GetType().Name);
            throw;
        }
    }

    /// <summary>
    /// Deactivates the generated actor and releases resources.
    /// </summary>
    public override async Task OnDeactivateAsync(DeactivationReason reason, CancellationToken cancellationToken)
    {
        try
        {
            _logger.LogInformation(
                "Deactivating generated actor {ActorType} (Reason: {Reason}, " +
                "Messages: {TotalMessages}, GPU: {GpuCount}, CPU: {CpuCount})",
                GetType().Name,
                reason.ReasonCode,
                _totalMessagesProcessed,
                _gpuExecutions,
                _cpuFallbacks);

            // Allow derived class to cleanup
            await CleanupActorAsync(cancellationToken);

            // Release GPU state if allocated
            if (_stateHandle != null && _ringKernelBridge != null)
            {
                try
                {
                    await _ringKernelBridge.ReleaseStateAsync(_stateHandle, cancellationToken);
                    _logger.LogDebug(
                        "Released GPU state for actor {ActorId}",
                        _stateHandle.ActorId);
                }
                catch (Exception releaseEx)
                {
                    _logger.LogWarning(
                        releaseEx,
                        "Failed to release GPU state for actor {ActorType}",
                        GetType().Name);
                }

                _stateHandle = null;
            }

            _logger.LogInformation(
                "Generated actor {ActorType} deactivated successfully",
                GetType().Name);
        }
        catch (Exception ex)
        {
            _logger.LogError(
                ex,
                "Error during generated actor {ActorType} deactivation",
                GetType().Name);
            // Don't rethrow - deactivation should complete
        }
    }

    /// <summary>
    /// Invokes a GPU handler with automatic CPU fallback.
    /// </summary>
    /// <typeparam name="TRequest">Request message type (blittable struct)</typeparam>
    /// <typeparam name="TResponse">Response message type (blittable struct)</typeparam>
    /// <param name="handlerId">Handler ID from generated code</param>
    /// <param name="request">Request payload</param>
    /// <param name="gpuHandler">GPU kernel execution delegate</param>
    /// <param name="cpuFallback">CPU fallback execution delegate</param>
    /// <param name="cancellationToken">Cancellation token</param>
    /// <returns>Response from handler execution</returns>
    protected async Task<TResponse> InvokeHandlerAsync<TRequest, TResponse>(
        int handlerId,
        TRequest request,
        Func<TRequest, TState, (TResponse response, TState newState)> gpuHandler,
        Func<TRequest, TState, (TResponse response, TState newState)> cpuFallback,
        CancellationToken cancellationToken = default)
        where TRequest : unmanaged
        where TResponse : unmanaged
    {
        if (!_isInitialized)
        {
            throw new InvalidOperationException(
                "Actor is not initialized. Cannot invoke handler.");
        }

        // Update HLC timestamp
        CurrentTimestamp = CurrentTimestamp.Increment(HybridTimestamp.GetCurrentPhysicalTimeNanos());

        var startTicks = Environment.TickCount64;

        try
        {
            (TResponse response, TState newState) result;

            if (_isGpuAvailable)
            {
                try
                {
                    // Attempt GPU execution
                    result = await ExecuteOnGpuAsync(handlerId, request, gpuHandler, cancellationToken);
                    Interlocked.Increment(ref _gpuExecutions);
                }
                catch (Exception ex)
                {
                    _logger.LogWarning(
                        ex,
                        "GPU execution failed for handler {HandlerId}, falling back to CPU",
                        handlerId);

                    // CPU fallback on GPU failure
                    result = cpuFallback(request, State);
                    Interlocked.Increment(ref _cpuFallbacks);
                }
            }
            else
            {
                // Direct CPU execution
                result = cpuFallback(request, State);
                Interlocked.Increment(ref _cpuFallbacks);
            }

            // Update state
            State = result.newState;

            // Update metrics
            Interlocked.Increment(ref _totalMessagesProcessed);
            RecordHandlerMetrics(handlerId, Environment.TickCount64 - startTicks, true);

            return result.response;
        }
        catch (Exception ex)
        {
            RecordHandlerMetrics(handlerId, Environment.TickCount64 - startTicks, false);
            _logger.LogError(
                ex,
                "Handler {HandlerId} failed for actor {ActorType}",
                handlerId,
                GetType().Name);
            throw;
        }
    }

    /// <summary>
    /// Invokes a fire-and-forget GPU handler.
    /// </summary>
    /// <typeparam name="TRequest">Request message type (blittable struct)</typeparam>
    /// <param name="handlerId">Handler ID from generated code</param>
    /// <param name="request">Request payload</param>
    /// <param name="gpuHandler">GPU kernel execution delegate</param>
    /// <param name="cpuFallback">CPU fallback execution delegate</param>
    /// <param name="cancellationToken">Cancellation token</param>
    protected async Task InvokeFireAndForgetHandlerAsync<TRequest>(
        int handlerId,
        TRequest request,
        FireAndForgetHandler<TRequest, TState> gpuHandler,
        FireAndForgetHandler<TRequest, TState> cpuFallback,
        CancellationToken cancellationToken = default)
        where TRequest : unmanaged
    {
        if (!_isInitialized)
        {
            throw new InvalidOperationException(
                "Actor is not initialized. Cannot invoke handler.");
        }

        // Update HLC timestamp
        CurrentTimestamp = CurrentTimestamp.Increment(HybridTimestamp.GetCurrentPhysicalTimeNanos());

        var startTicks = Environment.TickCount64;

        try
        {
            if (_isGpuAvailable)
            {
                try
                {
                    await ExecuteFireAndForgetOnGpuAsync(handlerId, request, gpuHandler, cancellationToken);
                    Interlocked.Increment(ref _gpuExecutions);
                }
                catch (Exception ex)
                {
                    _logger.LogWarning(
                        ex,
                        "GPU execution failed for fire-and-forget handler {HandlerId}, falling back to CPU",
                        handlerId);

                    cpuFallback(request, ref State);
                    Interlocked.Increment(ref _cpuFallbacks);
                }
            }
            else
            {
                cpuFallback(request, ref State);
                Interlocked.Increment(ref _cpuFallbacks);
            }

            Interlocked.Increment(ref _totalMessagesProcessed);
            RecordHandlerMetrics(handlerId, Environment.TickCount64 - startTicks, true);
        }
        catch (Exception ex)
        {
            RecordHandlerMetrics(handlerId, Environment.TickCount64 - startTicks, false);
            _logger.LogError(
                ex,
                "Fire-and-forget handler {HandlerId} failed for actor {ActorType}",
                handlerId,
                GetType().Name);
            throw;
        }
    }

    /// <summary>
    /// Gets metrics for a specific handler.
    /// </summary>
    /// <param name="handlerId">Handler ID</param>
    /// <returns>Handler metrics, or null if no data</returns>
    public HandlerMetrics? GetHandlerMetrics(int handlerId)
    {
        return _handlerMetrics.TryGetValue(handlerId, out var metrics) ? metrics : null;
    }

    /// <summary>
    /// Gets metrics for all handlers.
    /// </summary>
    /// <returns>Dictionary of handler ID to metrics</returns>
    public IReadOnlyDictionary<int, HandlerMetrics> GetAllHandlerMetrics()
    {
        return _handlerMetrics;
    }

    /// <summary>
    /// Gets actor telemetry data.
    /// </summary>
    public GeneratedActorTelemetry GetTelemetry()
    {
        return new GeneratedActorTelemetry(
            ActorType: GetType().Name,
            ActorId: TryGetActorId(),
            GpuDeviceId: _gpuDeviceId,
            IsGpuAvailable: _isGpuAvailable,
            TotalMessages: _totalMessagesProcessed,
            GpuExecutions: _gpuExecutions,
            CpuFallbacks: _cpuFallbacks,
            CurrentTimestamp: CurrentTimestamp);
    }

    /// <summary>
    /// Safely gets the actor ID, handling both Orleans runtime and test contexts.
    /// </summary>
    /// <returns>Actor ID string, or grain context ID as fallback for tests</returns>
    private string TryGetActorId()
    {
        try
        {
            return this.GetPrimaryKeyString();
        }
        catch
        {
            // In test context, GetPrimaryKeyString() may throw
            // Fall back to grain context ID
            return _grainContext.GrainId.ToString();
        }
    }

    /// <summary>
    /// Override to configure actor-specific resources.
    /// </summary>
    protected virtual Task ConfigureActorAsync(CancellationToken cancellationToken)
    {
        return Task.CompletedTask;
    }

    /// <summary>
    /// Override to cleanup actor-specific resources.
    /// </summary>
    protected virtual Task CleanupActorAsync(CancellationToken cancellationToken)
    {
        return Task.CompletedTask;
    }

    /// <summary>
    /// Override to determine GPU device placement.
    /// </summary>
    protected virtual Task<int> DetermineGpuDevicePlacementAsync(CancellationToken cancellationToken)
    {
        return Task.FromResult(0);
    }

    /// <summary>
    /// Override to check GPU availability.
    /// </summary>
    protected virtual Task<bool> CheckGpuAvailabilityAsync(CancellationToken cancellationToken)
    {
        // Default: CPU fallback mode
        // Real implementation would check DotCompute device availability
        return Task.FromResult(false);
    }

    #region GPU Execution via Ring Kernel Bridge

    /// <summary>
    /// Executes a handler on GPU using the ring kernel bridge.
    /// </summary>
    /// <remarks>
    /// When a ring kernel bridge is available, this method uses the bridge's
    /// ExecuteHandlerAsync to dispatch the handler to GPU. The bridge handles:
    /// - GPU memory management (via GpuStateHandle)
    /// - Request/Response serialization
    /// - Ring kernel message passing
    /// - State synchronization
    ///
    /// When no bridge is available or GPU execution fails, falls back to the
    /// provided gpuHandler delegate which executes on CPU.
    /// </remarks>
    private async Task<(TResponse response, TState newState)> ExecuteOnGpuAsync<TRequest, TResponse>(
        int handlerId,
        TRequest request,
        Func<TRequest, TState, (TResponse response, TState newState)> gpuHandler,
        CancellationToken cancellationToken)
        where TRequest : unmanaged
        where TResponse : unmanaged
    {
        // Use bridge if available and we have a valid state handle
        if (_ringKernelBridge != null && _stateHandle != null && _stateHandle.IsValid)
        {
            var kernelId = GetKernelId();
            var result = await _ringKernelBridge.ExecuteHandlerAsync<TRequest, TResponse, TState>(
                kernelId,
                handlerId,
                request,
                _stateHandle,
                cancellationToken);

            if (result.Success)
            {
                // Sync shadow state
                _stateHandle.ShadowState = result.NewState;
                return (result.Response, result.NewState);
            }

            // GPU execution failed, fall through to CPU handler
            _logger.LogWarning(
                "GPU handler execution failed for handler {HandlerId} (ErrorCode: {ErrorCode}), using CPU fallback",
                handlerId,
                result.ErrorCode);
        }

        // CPU execution via delegate
        var cpuResult = gpuHandler(request, State);

        // Sync to shadow state if handle exists
        if (_stateHandle != null)
        {
            _stateHandle.ShadowState = cpuResult.newState;
        }

        return cpuResult;
    }

    /// <summary>
    /// Executes a fire-and-forget handler on GPU using the ring kernel bridge.
    /// </summary>
    private async Task ExecuteFireAndForgetOnGpuAsync<TRequest>(
        int handlerId,
        TRequest request,
        FireAndForgetHandler<TRequest, TState> gpuHandler,
        CancellationToken cancellationToken)
        where TRequest : unmanaged
    {
        // Use bridge if available and we have a valid state handle
        if (_ringKernelBridge != null && _stateHandle != null && _stateHandle.IsValid)
        {
            var kernelId = GetKernelId();
            var newState = await _ringKernelBridge.ExecuteFireAndForgetAsync<TRequest, TState>(
                kernelId,
                handlerId,
                request,
                _stateHandle,
                cancellationToken);

            // Update local state and shadow copy
            State = newState;
            _stateHandle.ShadowState = newState;
            return;
        }

        // CPU execution via delegate
        gpuHandler(request, ref State);

        // Sync to shadow state if handle exists
        if (_stateHandle != null)
        {
            _stateHandle.ShadowState = State;
        }
    }

    /// <summary>
    /// Gets the kernel ID for this actor type.
    /// Override in generated actors to provide the correct kernel ID.
    /// </summary>
    protected virtual string GetKernelId()
    {
        return $"RingKernel/{GetType().Name}";
    }

    #endregion

    private void RecordHandlerMetrics(int handlerId, long elapsedMs, bool success)
    {
        _handlerMetrics.AddOrUpdate(
            handlerId,
            _ => new HandlerMetrics(
                HandlerId: handlerId,
                InvocationCount: 1,
                SuccessCount: success ? 1 : 0,
                FailureCount: success ? 0 : 1,
                TotalElapsedMs: elapsedMs,
                MinLatencyMs: elapsedMs,
                MaxLatencyMs: elapsedMs),
            (_, existing) => existing with
            {
                InvocationCount = existing.InvocationCount + 1,
                SuccessCount = existing.SuccessCount + (success ? 1 : 0),
                FailureCount = existing.FailureCount + (success ? 0 : 1),
                TotalElapsedMs = existing.TotalElapsedMs + elapsedMs,
                MinLatencyMs = Math.Min(existing.MinLatencyMs, elapsedMs),
                MaxLatencyMs = Math.Max(existing.MaxLatencyMs, elapsedMs)
            });
    }
}

/// <summary>
/// Metrics for a generated handler.
/// </summary>
/// <param name="HandlerId">Handler ID</param>
/// <param name="InvocationCount">Total invocations</param>
/// <param name="SuccessCount">Successful invocations</param>
/// <param name="FailureCount">Failed invocations</param>
/// <param name="TotalElapsedMs">Total elapsed time in milliseconds</param>
/// <param name="MinLatencyMs">Minimum latency in milliseconds</param>
/// <param name="MaxLatencyMs">Maximum latency in milliseconds</param>
public sealed record HandlerMetrics(
    int HandlerId,
    long InvocationCount,
    long SuccessCount,
    long FailureCount,
    long TotalElapsedMs,
    long MinLatencyMs,
    long MaxLatencyMs)
{
    /// <summary>
    /// Gets the average latency in milliseconds.
    /// </summary>
    public double AverageLatencyMs => InvocationCount > 0
        ? (double)TotalElapsedMs / InvocationCount
        : 0;

    /// <summary>
    /// Gets the success rate (0.0 to 1.0).
    /// </summary>
    public double SuccessRate => InvocationCount > 0
        ? (double)SuccessCount / InvocationCount
        : 0;
}

/// <summary>
/// Telemetry data for generated actors.
/// </summary>
/// <param name="ActorType">Actor type name</param>
/// <param name="ActorId">Actor ID</param>
/// <param name="GpuDeviceId">GPU device ID</param>
/// <param name="IsGpuAvailable">Whether GPU is available</param>
/// <param name="TotalMessages">Total messages processed</param>
/// <param name="GpuExecutions">GPU execution count</param>
/// <param name="CpuFallbacks">CPU fallback count</param>
/// <param name="CurrentTimestamp">Current HLC timestamp</param>
public sealed record GeneratedActorTelemetry(
    string ActorType,
    string ActorId,
    int GpuDeviceId,
    bool IsGpuAvailable,
    long TotalMessages,
    long GpuExecutions,
    long CpuFallbacks,
    HybridTimestamp CurrentTimestamp)
{
    /// <summary>
    /// Gets the GPU execution ratio (0.0 to 1.0).
    /// </summary>
    public double GpuExecutionRatio => TotalMessages > 0
        ? (double)GpuExecutions / TotalMessages
        : 0;
}
